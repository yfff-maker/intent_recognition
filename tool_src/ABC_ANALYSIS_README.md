# ABC策略对比分析工具使用说明

## 📖 功能说明

这个脚本专门用于分析Bandit架构中，A/B/C三种窗口策略在不同异常点的表现差异。

### 核心分析维度

1. **总体性能对比**
   - 平均置信度、标准差、中位数
   - 高置信度(>0.8)比例、低置信度(<0.5)比例
   - 策略B/C相对A的提升幅度

2. **按异常类型对比**
   - 不同异常类型（重复点击、长时间停留等）下的ABC表现

3. **按参与者对比**
   - 每个参与者在ABC策略下的置信度差异
   - 找出C策略提升最大/最小的参与者

4. **按异常点对比**（最详细）
   - 每个异常点的ABC置信度
   - C-A、B-A差异值
   - 最佳策略判定
   - 意图推断一致性

---

## 🚀 使用方法

### 前置条件

确保已运行过Bandit版本：
```bash
python main_bandit.py
```

这会生成 `output/intent_inference_results_bandit.xlsx`

### 运行分析

```bash
cd tool_src
python analyze_abc_strategies.py
```

---

## 📊 输出文件

### 1. `abc_strategy_analysis_report.xlsx`

包含4个Sheet：

| Sheet名 | 内容 | 关键列 |
|---------|------|--------|
| 总体对比 | ABC策略的总体统计 | MeanConfidence, HighConfRate, ImprovementVsA |
| 按异常类型 | 不同异常类型下的表现 | AnomalyType, Strategy, MeanConfidence |
| 按参与者 | 每个参与者的ABC对比 | Participant, Strategy_A/B/C_Mean, C_vs_A |
| 按异常点 | 每个异常点的详细数据 | AnomalyID, Conf_A/B/C, C_minus_A, Intent_Agreement |

---

### 2. `abc_strategy_comparison.png` - 综合对比图

包含7个子图：

```
┌─────────────────────┬─────────────────────┬─────────────────────┐
│ 1. 总体置信度柱状图  │ 2. 置信度分布箱线图  │ 3. 高置信度比例     │
├─────────────────────┴─────────────────────┼─────────────────────┤
│ 4. 按异常类型的对比                        │ 5. 参与者提升散点图  │
├────────────────┬────────────────┬─────────┴─────────────────────┤
│ 6. 最佳策略饼图 │ 7. 置信度时序趋势（折线图）                     │
└────────────────┴────────────────┴──────────────────────────────┘
```

**图表说明：**
- **图1**：直观对比ABC平均置信度
- **图2**：看置信度的分布和离散程度
- **图3**：高置信度样本的比例对比
- **图4**：不同异常类型（如重复点击、长时间停留）下ABC的差异
- **图5**：每个参与者的C相对A提升，找出受益最大的参与者
- **图6**：统计哪个策略最常成为"最佳"
- **图7**：按时间轴看ABC的表现趋势

---

### 3. `abc_anomaly_detail_comparison.png` - 异常点级详细对比

包含4个子图：

```
┌─────────────────────────┬─────────────────────────┐
│ 1. C-A差异分布直方图     │ 2. B-A vs C-A散点图     │
├─────────────────────────┼─────────────────────────┤
│ 3. 意图一致性柱状图      │ 4. 按异常类型的C-A提升  │
└─────────────────────────┴─────────────────────────┘
```

**图表说明：**
- **图1**：C策略相对A的差异分布，看是普遍提升还是部分提升
- **图2**：判断B和C哪个提升更大，是否存在线性关系
- **图3**：ABC三种策略推断的意图是否一致（一致性高说明鲁棒）
- **图4**：哪些异常类型更适合用长窗口（C策略）

---

## 📈 示例输出

### 控制台输出示例

```
================================================================================
📊 ABC策略总体性能对比
================================================================================

策略 A:
  样本数: 150
  平均置信度: 0.6234
  中位数置信度: 0.6500
  标准差: 0.1823
  高置信度(>0.8)比例: 18.67%
  低置信度(<0.5)比例: 23.33%

策略 B:
  样本数: 150
  平均置信度: 0.6891
  中位数置信度: 0.7100
  标准差: 0.1654
  高置信度(>0.8)比例: 28.00%
  低置信度(<0.5)比例: 15.33%

策略 C:
  样本数: 150
  平均置信度: 0.7456
  中位数置信度: 0.7650
  标准差: 0.1512
  高置信度(>0.8)比例: 38.67%
  低置信度(<0.5)比例: 9.33%

📈 相对于策略A的提升:
  B vs A: +0.0657 (+10.54%)
  C vs A: +0.1222 (+19.61%)

================================================================================
🔍 关键发现总结
================================================================================

1. 总体置信度提升:
   - 策略A（短窗口）: 0.6234
   - 策略B（中窗口）: 0.6891 (+10.54%)
   - 策略C（长窗口）: 0.7456 (+19.61%)

   ✅ 结论: 更长的上下文窗口带来更高的置信度！

2. 意图推断一致性:
   - ABC三策略推断相同意图的比例: 72.3%
   ✅ 策略间一致性高，结果可靠

3. 最佳策略分布:
   - 策略A: 25 次 (16.7%)
   - 策略B: 42 次 (28.0%)
   - 策略C: 83 次 (55.3%)
```

---

## 🔍 如何解读结果

### 场景1：C策略明显优于A/B

**现象：**
- C的平均置信度比A高15%+
- C的高置信度比例>40%
- 最佳策略分布中C占比>50%

**解释：**
✅ **长上下文窗口有效！**
- 用户的意图线索分布在较长时间跨度内
- 早期尝试、中间探索、最终行为共同决定意图
- 支持你的假设："长序列信息对意图识别至关重要"

**论文中可以说：**
> "实验结果表明，策略C（左200右50个事件）相比策略A（左右各2个事件）
> 在平均置信度上提升了19.61%，高置信度样本比例从18.67%提升至38.67%。
> 这验证了我们的假设：**用户意图的关键线索往往分布在长时间跨度内**，
> 仅依靠异常点附近的短窗口会导致信息不足。"

---

### 场景2：C策略效果与B相近

**现象：**
- C比B只高2-5%
- 最佳策略分布中B和C接近

**解释：**
⚠️ **存在最优窗口长度**
- 策略B（41个事件）已经捕获了大部分关键信息
- 策略C虽然更长，但引入了一些噪音
- 边际收益递减

**论文中可以说：**
> "策略B和C的性能接近，说明存在一个最优的上下文窗口长度。
> 超过某个阈值后，额外的历史信息带来的增益有限，
> 甚至可能引入噪音干扰。这为**自适应窗口选择**提供了方向。"

---

### 场景3：不同异常类型差异大

**现象：**
- "重复点击"类型：C比A高30%
- "长时间停留"类型：C比A只高5%

**解释：**
🎯 **任务导向的窗口策略**
- 某些异常（如重复点击）需要追溯更早的尝试
- 某些异常（如长时间停留）本身就包含足够信息

**论文中可以说：**
> "不同异常类型对上下文长度的需求不同。'重复交互'类异常
> 在策略C下置信度提升显著（+30.2%），而'长时间停留'类异常
> 在策略B下已达到最优。这启发我们设计**异常类型感知的动态窗口策略**。"

---

## 🎯 下一步分析建议

### 1. 深入分析"意图不一致"的异常点

```python
# 在Excel中筛选 Intent_Agreement = FALSE 的行
# 手工检查：为什么ABC给出不同意图？
```

### 2. 对比Baseline（简单记忆库）

```bash
# 已经有了 compare_results.py
# 可以对比：Bandit-C vs Baseline-C
```

### 3. 消融实验：窗口大小的精细调优

修改 `config.py`：
```python
STRATEGY_WINDOWS = {
    "A": {"k_left": 2, "k_right": 2},
    "B": {"k_left": 20, "k_right": 20},
    "C": {"k_left": 200, "k_right": 50},
    "D": {"k_left": 100, "k_right": 30},  # 新增中间值
    "E": {"k_left": 300, "k_right": 50},  # 新增更长值
}
```

---

## 📞 常见问题

**Q1: 为什么某些参与者C策略反而更差？**

A: 可能原因：
1. 该参与者任务时间短，长窗口没有足够信息
2. 该参与者行为模式简单，短窗口已经足够
3. 长窗口引入了噪音（如早期无关的探索行为）

**Q2: 如何判断结果是否有统计显著性？**

A: 可以在Excel中对导出的数据做t检验：
```python
from scipy import stats
conf_a = df[df['Strategy']=='A']['Confidence']
conf_c = df[df['Strategy']=='C']['Confidence']
t_stat, p_value = stats.ttest_rel(conf_a, conf_c)
print(f"p-value: {p_value}")
# p < 0.05 说明差异显著
```

**Q3: 为什么生成图表时报错？**

A: 确保安装了必要的库：
```bash
pip install matplotlib seaborn pandas openpyxl
```

---

## 📚 相关文件

- `main_bandit.py` - 生成Bandit结果
- `compare_results.py` - 对比Baseline vs Bandit
- `analyze_abc_strategies.py` - 本脚本，ABC策略对比

---

生成日期: 2026-02-04
