# Multi-modal User Behavior Dataset for Evolutionary Requirements Elicitation

This dataset contains anonymized multi-modal user behavior data collected from 20 participants (P1-P20) during a controlled user study. The study aimed to elicit evolutionary requirements for a software system by analyzing user interactions, eye movements, and feedback.

This dataset supports the research presented in the paper: **"Goal-aware User Behavior Modeling via Multi-modal Data Fusion for Evolutionary Requirements Elicitation"**.

## Dataset Structure

The dataset is organized by participant ID. Each participant folder contains the following files:

```
anonymous_data/
├── P1/
│   ├── raw_data/                 # Raw logs generated by the data collection tool
│   ├── task_recording_P1.mp4     # Screen and facial recording of the session
│   ├── behavior_sequences.json   # Serialized user behavior sequences (Action, Time, Object)
│   └── interview_log.txt         # Transcribed and translated post-task interview feedback
├── P2/
│   ...
├── P20/
│   ...
└── README.md                     # This file
```

## File Descriptions

### 1. `task_recording_P{ID}.mp4`
- **Description**: A video recording of the participant's screen and/or face during the experiment.
- **Usage**: Used for ground-truth verification and qualitative analysis of user context. In the proposed approach, frames from these videos are used to extract GUI information for the LLM-based inference module.

### 2. `behavior_sequences.json`
- **Description**: A structured JSON file containing the sequence of user actions.
- **Format**: A list of event objects. Each object typically includes:
    - `operationId`: Unique identifier for the event.
    - `page`: The active page or interface.
    - `widget`: The UI element interacted with.
    - `startTimeTick`: Timestamp.
    - `duration`: Duration of the action.
- **Relation to Paper**: This corresponds to the **Formalized Behavior Sequence (S)** described in Section III.A. It is the primary input for the **Goal Matching Algorithm** and **Anomalous Behavior Pattern Mining**.

### 3. `raw_data/`
- **Description**: Contains the raw, unprocessed data logs from the eye-tracker and logging software.
- **Contents**: May include detailed coordinate data, raw eye-tracking streams, and system event logs.
- **Relation to Paper**: This is the source for the **Multi-modal Data Fusion** process.

### 4. `interview_log.txt`
- **Description**: Textual records of the post-experiment interviews.
- **Language**: English (Translated from original Chinese).
- **Relation to Paper**: Used as the **Ground Truth** for evaluating the effectiveness of the requirements elicitation approach. The requirements inferred by the LLM are compared against these self-reported issues to calculate Recall (as mentioned in the Evaluation section).

## Application of the Dataset

Researchers can use this dataset to:
1.  **Replicate the Study**: Apply the proposed Goal-aware Behavior Modeling and Pattern Mining algorithms to reproduce the results.
2.  **Train/Test New Models**: Use the behavior sequences and interview labels to train new machine learning models for usability issue detection.
3.  **LLM Prompt Engineering**: Use the video frames and behavior logs to design and test new Prompt Engineering strategies for automated requirements elicitation.

## Notes
- All personal identifiable information (PII) has been removed or anonymized.
- Participant IDs (P1-P20) are randomly assigned and do not correspond to the original alphabetical order of names.
